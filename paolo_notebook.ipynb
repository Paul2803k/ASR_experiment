{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASR: Experiment 3, Whisper vs Wav2Vec2 vs Vosk"
      ],
      "metadata": {
        "id": "-Zr6ZTbGMOFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shared variables\n",
        "\n",
        "# indicates how many lines of the data sets we should go through (max for the drive is 3994)\n",
        "LIMIT = 2000\n",
        "# indicates if we need to install the vosk model (since it takes a bit, 1.8 GB)\n",
        "INSTALL = False\n",
        "# indicates if we need to convert the files from .mp3 to .wav for Vosk\n",
        "CONVERT = False\n",
        "# indicates if we want to perform a clean run (get rid of everything installed for Vosk)\n",
        "CLEAN = False"
      ],
      "metadata": {
        "id": "sm2fBwJrVca-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up functions for a clean run, plus removes th egarbage from the installation\n",
        "import shutil\n",
        "\n",
        "if CLEAN:\n",
        "  try:\n",
        "    shutil.rmtree('/content/vosk-model-en-us-0.22')\n",
        "    shutil.rmtree('/content/vosk-api')\n",
        "    shutil.rmtree('/content/sample_data')\n",
        "  except Exception:\n",
        "    print(\"No folder to clean, continuing..\")"
      ],
      "metadata": {
        "id": "UF_W4Yt1Uscz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shared install\n",
        "!pip install tqdm\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH8cm51PHxN4",
        "outputId": "452d7f98-dcec-4b57-9675-1a25e2608b3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shared imports\n",
        "from os import path\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import string\n",
        "import re\n",
        "import math\n",
        "import torch\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nsXkvDc6G_ON"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting the drive with the dataset\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6vWI3QDoneiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a40dbc-d4c1-408c-c746-42e1d56963b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading in the dataset csv\n",
        "# data keys are: filename, text, up_votes, down_votes, age, gender, accent and duration\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/cv-valid-test.csv\")"
      ],
      "metadata": {
        "id": "zda118auiipx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shared utility functions\n",
        "\n",
        "# gets short, average and long keywords in a sentence\n",
        "def grab_keywords(sentence):\n",
        "    words = sentence.split(\" \")\n",
        "    keywords = [[],[],[]]\n",
        "    for i in words:\n",
        "        if len(i) <= 3:\n",
        "            keywords[0].append(i)\n",
        "    for i in words:\n",
        "        if len(i) == 4 or len(i) == 5:\n",
        "            keywords[1].append(i)\n",
        "    for i in words:\n",
        "        if len(i) > 5:\n",
        "            keywords[2].append(i)\n",
        "    return [\" \".join(keywords[0]),\" \".join(keywords[1]),\" \".join(keywords[2])]\n",
        "\n",
        "# mitch scoring stuff\n",
        "def cosinesimularity(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "    sum1 = sum([vec1[x]**2 for x in list(vec1.keys())])\n",
        "    sum2 = sum([vec2[x]**2 for x in list(vec2.keys())])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "def text_to_vector(text):\n",
        "    WORD = re.compile(r\"\\w+\")\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "def get_cosinesimularity(text1, text2):\n",
        "    if text1 == '' and text2 == '':\n",
        "      return -1\n",
        "    vector1 = text_to_vector(text1.lower().translate(str.maketrans('', '', string.punctuation)))\n",
        "    vector2 = text_to_vector(text2.lower().translate(str.maketrans('', '', string.punctuation)))\n",
        "    cosine = cosinesimularity(vector1, vector2)\n",
        "    return cosine\n",
        "\n",
        "# used for final prints\n",
        "def get_label(index):\n",
        "    if index == 0:\n",
        "      return 'short'\n",
        "    if index == 1:\n",
        "      return 'average'\n",
        "    if index == 2:\n",
        "      return 'long'"
      ],
      "metadata": {
        "id": "EfFPZVbxk3q9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Whisper**"
      ],
      "metadata": {
        "id": "bAt6quvVP7as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# whisper imports\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
      ],
      "metadata": {
        "id": "q9SATwJCHUKm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model and processor\n",
        "whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-base.en\")\n",
        "whisper_med_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base.en\")"
      ],
      "metadata": {
        "id": "QzG-B8jPHT52"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WHISPER SCORE\n",
        "\n",
        "scores = []\n",
        "k_scores = [[],[],[]]\n",
        "\n",
        "print(\"[!] Starting experiment\")\n",
        "\n",
        "for index, samp in enumerate(tqdm(data.iterrows())):\n",
        "  # limiter for testing\n",
        "  if index == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/\"+samp[1][0]\n",
        "\n",
        "  # load the sample\n",
        "  waveform, sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "  # whisper only works with 16k sample rate so if we have others we convert it\n",
        "  if sample_rate != 16000:\n",
        "     waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)\n",
        "\n",
        "  # tokenize\n",
        "  input_features = whisper_processor(waveform.numpy()[0], sampling_rate=16000, return_tensors=\"pt\").input_features\n",
        "\n",
        "  # generate token ids\n",
        "  predicted_ids = whisper_med_model.generate(input_features)\n",
        "\n",
        "  # decode token ids to text\n",
        "  transcript = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "  text = samp[1][1]\n",
        "\n",
        "  # filling scores\n",
        "  score = get_cosinesimularity(text, transcript)\n",
        "  scores.append(score)\n",
        "\n",
        "  # get keywords of different length\n",
        "  keywords_tr = grab_keywords(transcript)\n",
        "  keywords_te = grab_keywords(text)\n",
        "\n",
        "  # debug print\n",
        "  print()\n",
        "  # print(text)\n",
        "  # print(transcript)\n",
        "  # print(keywords_tr)\n",
        "  # print(keywords_te)\n",
        "\n",
        "  # filling scores\n",
        "  for i in range(3):\n",
        "    k_score =  get_cosinesimularity(keywords_tr[i], keywords_te[i])\n",
        "    if k_score != -1:\n",
        "      k_scores[i].append(score)\n",
        "\n",
        "print(\"[!] End of experiment, aggregating scores\")\n",
        "\n",
        "print(\"[*] Mean scores\")\n",
        "\n",
        "print(\"Mean score for full sentences: {}\".format(np.mean(scores)))\n",
        "for i in range(3):\n",
        "    print(\"Mean score for {} words: {}\".format(get_label(i), np.mean(k_scores[i])))\n",
        "\n",
        "print(\"[*] Median scores\")\n",
        "\n",
        "print(\"Median score for full sentences: {}\".format(np.median(scores)))\n",
        "for i in range(3):\n",
        "    print(\"Median score for {} words: {}\".format(get_label(i), np.median(k_scores[i])))\n",
        "\n",
        "print(\"[!] Complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ByB8iM6HTqu",
        "outputId": "8b8c76b1-399b-4c81-dcfd-f58007ef2e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[!] Starting experiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "1it [00:11, 11.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:14,  6.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:18,  5.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:21,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:23,  3.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [00:25,  3.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [00:27,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [00:30,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [00:32,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [00:35,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [00:37,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [00:40,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [00:42,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [00:44,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [00:47,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [00:50,  2.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [00:52,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [00:55,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [00:57,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [00:59,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [01:01,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r22it [01:04,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r23it [01:06,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [01:08,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [01:11,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [01:13,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [01:15,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r28it [01:18,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r29it [01:20,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [01:22,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r31it [01:24,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r32it [01:27,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r33it [01:29,  2.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r34it [01:32,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r35it [01:34,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r36it [01:36,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r37it [01:39,  2.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r38it [01:42,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wav2vec**"
      ],
      "metadata": {
        "id": "K8GHQ-jaPkub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC"
      ],
      "metadata": {
        "id": "tn6cCBQImQ_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load processor and model\n",
        "wav2vec_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "wav2vec_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ],
      "metadata": {
        "id": "dMWhWYP83Bid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WAV2VEC SCORE\n",
        "\n",
        "scores = []\n",
        "k_scores = [[],[],[]]\n",
        "\n",
        "print(\"[!] Starting experiment\")\n",
        "\n",
        "for index, samp in enumerate(tqdm(data.iterrows())):\n",
        "  # limiter for testing\n",
        "  if index == LIMIT:\n",
        "    break\n",
        "  file_path = \"/content/drive/MyDrive/\"+samp[1][0]\n",
        "\n",
        "  # load the sample\n",
        "  waveform, sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "  # wav2vec only works with 16k sample rate so if we have others we convert it\n",
        "  if sample_rate != 16000:\n",
        "     waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)\n",
        "\n",
        "  # tokenize\n",
        "  input_values = wav2vec_processor(waveform.numpy()[0], sampling_rate=16000, return_tensors=\"pt\", padding=\"longest\").input_values\n",
        "\n",
        "  # retrieve logits\n",
        "  logits = wav2vec_model(input_values).logits\n",
        "\n",
        "  # take argmax and decode\n",
        "  predicted_ids = torch.argmax(logits, dim=-1)\n",
        "  transcript = wav2vec_processor.batch_decode(predicted_ids)[0]\n",
        "\n",
        "  text = samp[1][1]\n",
        "\n",
        "  # filling scores\n",
        "  score = get_cosinesimularity(text, transcript)\n",
        "  scores.append(score)\n",
        "\n",
        "  # get keywords of different length\n",
        "  keywords_tr = grab_keywords(transcript)\n",
        "  keywords_te = grab_keywords(text)\n",
        "\n",
        "  # debug print\n",
        "  print()\n",
        "  # print(text)\n",
        "  # print(transcript)\n",
        "  # print(keywords_tr)\n",
        "  # print(keywords_te)\n",
        "\n",
        "  # filling scores\n",
        "  for i in range(3):\n",
        "    k_score =  get_cosinesimularity(keywords_tr[i], keywords_te[i])\n",
        "    if k_score != -1:\n",
        "      k_scores[i].append(score)\n",
        "\n",
        "print(\"[!] End of experiment, aggregating scores\")\n",
        "\n",
        "print(\"[*] Mean scores\")\n",
        "\n",
        "print(\"Mean score for full sentences: {}\".format(np.mean(scores)))\n",
        "for i in range(3):\n",
        "    print(\"Mean score for {} words: {}\".format(get_label(i), np.mean(k_scores[i])))\n",
        "\n",
        "print(\"[*] Median scores\")\n",
        "\n",
        "print(\"Median score for full sentences: {}\".format(np.median(scores)))\n",
        "for i in range(3):\n",
        "    print(\"Median score for {} words: {}\".format(get_label(i), np.median(k_scores[i])))\n",
        "\n",
        "print(\"[!] Complete\")"
      ],
      "metadata": {
        "id": "dLuDaQ-y8_HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vosk**"
      ],
      "metadata": {
        "id": "AgLP7s_7SuRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install vosk api and pydub [once per session]\n",
        "!pip install vosk\n",
        "!pip install pydub"
      ],
      "metadata": {
        "id": "EJ4U0fJeHBuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get model [once per session]\n",
        "if INSTALL:\n",
        "  !wget https://alphacephei.com/kaldi/models/vosk-model-en-us-0.22.zip\n",
        "  !unzip vosk-model-en-us-0.22.zip"
      ],
      "metadata": {
        "id": "I5iN8bOIHDn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from pydub import AudioSegment\n",
        "import wave\n",
        "import json"
      ],
      "metadata": {
        "id": "N2qSW9_iHD0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert files for experiments [one time thing]\n",
        "if CONVERT:\n",
        "  for index, samp in enumerate(tqdm(data.iterrows())):\n",
        "    # get full path of sample\n",
        "    file_path = \"/content/drive/MyDrive/\"+samp[1][0]\n",
        "    # destination path for sample\n",
        "    dest = file_path.replace('.mp3', '.wav')\n",
        "    # we skip the ones already converted\n",
        "    if path.isfile(dest):\n",
        "      continue\n",
        "    # convert wav to mp3, vosk only uses WAV mono PCM\n",
        "    sound = AudioSegment.from_mp3(file_path)\n",
        "    sound.export(dest, format=\"wav\")\n",
        "    print()\n",
        "    print(\"Converted {} to {}\".format(file_path, dest))"
      ],
      "metadata": {
        "id": "S6y8d8A_3Epo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import model\n",
        "vosk_model = Model(\"/content/vosk-model-en-us-0.22\")"
      ],
      "metadata": {
        "id": "PyD228se_s1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VOSK SCORE\n",
        "\n",
        "scores = []\n",
        "k_scores = [[],[],[]]\n",
        "\n",
        "print(\"[!] Starting experiment\")\n",
        "\n",
        "for index, samp in enumerate(tqdm(data.iterrows())):\n",
        "  # limiter for testing\n",
        "  if index == LIMIT:\n",
        "    break\n",
        "\n",
        "  # get full path of sample\n",
        "  file_path = \"/content/drive/MyDrive/\"+samp[1][0]\n",
        "\n",
        "  # destination path for sample\n",
        "  dest = file_path.replace('.mp3', '.wav')\n",
        "\n",
        "  # open file\n",
        "  wf = wave.open(dest,\"rb\")\n",
        "\n",
        "  # check if the conversion is proper\n",
        "  if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
        "    exit (1)\n",
        "\n",
        "  # initialise recogniser\n",
        "  rec = KaldiRecognizer(vosk_model, wf.getframerate())\n",
        "\n",
        "  # recognition loop\n",
        "  while True:\n",
        "    d = wf.readframes(4000)\n",
        "    if len(d) == 0:\n",
        "        break\n",
        "    rec.AcceptWaveform(d)\n",
        "\n",
        "  text = samp[1].text\n",
        "  transcript = json.loads(rec.FinalResult())[\"text\"]\n",
        "\n",
        "  # filling scores\n",
        "  score = get_cosinesimularity(text, transcript)\n",
        "  scores.append(score)\n",
        "\n",
        "  # get keywords of different length\n",
        "  keywords_tr = grab_keywords(transcript)\n",
        "  keywords_te = grab_keywords(text)\n",
        "\n",
        "  # debug print\n",
        "  print()\n",
        "  # print(text)\n",
        "  # print(transcript)\n",
        "  # print(keywords_tr)\n",
        "  # print(keywords_te)\n",
        "\n",
        "  # filling scores\n",
        "  for i in range(3):\n",
        "    k_score =  get_cosinesimularity(keywords_tr[i], keywords_te[i])\n",
        "    if k_score != -1:\n",
        "      k_scores[i].append(score)\n",
        "\n",
        "print(\"[!] End of experiment, aggregating scores\")\n",
        "\n",
        "print(\"[*] Mean scores\")\n",
        "\n",
        "print(\"Mean score for full sentences: {}\".format(np.mean(scores)))\n",
        "for i in range(3):\n",
        "    print(\"Mean score for {} words: {}\".format(get_label(i), np.mean(k_scores[i])))\n",
        "\n",
        "print(\"[*] Median scores\")\n",
        "\n",
        "print(\"Median score for full sentences: {}\".format(np.median(scores)))\n",
        "for i in range(3):\n",
        "    print(\"Median score for {} words: {}\".format(get_label(i), np.median(k_scores[i])))\n",
        "\n",
        "print(\"[!] Complete\")"
      ],
      "metadata": {
        "id": "cTDEBaBAHEBc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}